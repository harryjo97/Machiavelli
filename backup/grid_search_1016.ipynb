{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import *\n",
    "import itertools\n",
    "\n",
    "import os\n",
    "\n",
    "import xgboost as xgb \n",
    "from xgboost import plot_importance , XGBClassifier\n",
    "\n",
    "import lightgbm as lgbm\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from keras.utils.np_utils import to_categorical \n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import *\n",
    "\n",
    "from tqdm import tqdm, notebook\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_original = pd.read_csv('./open data/train.csv')\n",
    "test_original = pd.read_csv('./open data/test_x.csv')\n",
    "train = train_original.copy()\n",
    "test = test_original.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill NA\n",
    "def fill_married(data):\n",
    "    pdata = data.copy()\n",
    "    pdata.loc[ (pdata.married==0)&(pdata.age_group=='10s'),'married' ] = 1\n",
    "    pdata.loc[ (pdata.married==0)&(pdata.age_group=='20s'),'married' ] = 1\n",
    "    pdata.loc[pdata.married==0,'married'] = 2\n",
    "    \n",
    "    return pdata\n",
    "\n",
    "def fill_education(data):\n",
    "    pdata = data.copy()\n",
    "    pdata.loc[(pdata.education==0)&(pdata.age_group=='10s'),'education'] = 2\n",
    "    pdata.loc[pdata.education==0,'education'] = 3\n",
    "\n",
    "    return pdata\n",
    "\n",
    "def fill_engnat(data):\n",
    "    pdata = data.copy()\n",
    "    pdata.loc[pdata.engnat==0,'engnat'] = 1\n",
    "    \n",
    "    return pdata\n",
    "\n",
    "def fill_hand(data):\n",
    "    pdata = data.copy()\n",
    "    pdata.loc[pdata.hand==0,'hand'] = 1\n",
    "    \n",
    "    return pdata\n",
    "# feature engineering\n",
    "def Mach_score(data):\n",
    "    pdata = data.copy()\n",
    "    Answers = []\n",
    "    for i in range(20):\n",
    "        Answers.append('Q'+chr(97+i)+'A')\n",
    "    reverse_col = ['QeA','QfA','QkA','QqA','QrA','QaA','QdA','QgA','QiA','QnA']\n",
    "    for col in reverse_col:\n",
    "        pdata[col] = -pdata[col]\n",
    "    pdata['Mach_score'] = pdata[Answers].sum(axis=1)\n",
    "    \n",
    "    return pdata\n",
    "\n",
    "def w_score(data):\n",
    "    pdata = data.copy()\n",
    "    wr = []\n",
    "    wf = []\n",
    "    for i in range(1,14):\n",
    "        wr.append(f'wr_{i:02d}')\n",
    "    for i in range(1,4):\n",
    "        # pdata[f'wf_{i:02d}'] = -pdata[f'wf_{i:02d}']\n",
    "        wf.append(f'wf_{i:02d}')\n",
    "    \n",
    "    pdata['wr'] = pdata[wr].sum(axis=1)\n",
    "    pdata['wf'] = pdata[wf].sum(axis=1)\n",
    "    \n",
    "    return pdata\n",
    "\n",
    "def TIPI(data):\n",
    "    pdata = data.copy()\n",
    "    pdata['tp_score_1'] = pdata['tp01'] - pdata['tp06']\n",
    "    pdata['tp_score_2'] = pdata['tp07'] - pdata['tp02']\n",
    "    pdata['tp_score_3'] = pdata['tp03'] - pdata['tp08']\n",
    "    pdata['tp_score_4'] = pdata['tp09'] - pdata['tp04']\n",
    "    pdata['tp_score_5'] = pdata['tp05'] - pdata['tp10']\n",
    "    \n",
    "    return pdata\n",
    "\n",
    "# drop outlier\n",
    "def drop_outlier(data, datatype):\n",
    "    \n",
    "    assert datatype == 'train' or datatype=='test', 'Wrong data type given'\n",
    "    \n",
    "    pdata = data.copy()\n",
    "    if datatype=='train':\n",
    "        \n",
    "        out_arr = []\n",
    "        out_arr.append( np.where(data['familysize']>=16)[0] )\n",
    "        out_arr.append( np.where(data.wr<=3)[0] )\n",
    "        out_arr.append( np.where(data.wf>=2)[0] )\n",
    "\n",
    "        out = []\n",
    "        for outarr in out_arr:\n",
    "            out = np.union1d(out, outarr)\n",
    "\n",
    "        pdata = data.drop(out)\n",
    "    \n",
    "    return pdata\n",
    "# feature banding\n",
    "def age_band(data):\n",
    "    pdata = data.copy()\n",
    "    pdata['age_group'].replace(['10s','20s','30s','40s','50s','60s','+70s'],[1,2,3,4,5,5,5],inplace=True)\n",
    "    \n",
    "    return pdata\n",
    "\n",
    "def E_band(data, num_band):\n",
    "    pdata = data.copy()\n",
    "    for i in range(20):\n",
    "        col = 'Q'+chr(i+97)+'E'\n",
    "        pdata[col] = pd.qcut(pdata[col],num_band)\n",
    "        unique = pdata[col].unique()\n",
    "        pdata[col].replace(unique,range(num_band),inplace=True)\n",
    "        \n",
    "    return pdata\n",
    "\n",
    "def family_band(data):\n",
    "    pdata = data.copy()\n",
    "    pdata.loc[pdata.familysize >= 4,'familysize'] = 4\n",
    "    \n",
    "    return pdata\n",
    "# categorical value to numerical value\n",
    "def cat_gender(data):\n",
    "    feature = 'gender'\n",
    "    pdata = data.copy()\n",
    "    pdata[feature].replace(['Male','Female'],[0,1],inplace=True)\n",
    "    \n",
    "    return pdata\n",
    "\n",
    "def cat_race(data):\n",
    "    feature = 'race'\n",
    "    pdata = data.copy()\n",
    "    unique = ['White', 'Asian', 'Other', 'Black', 'Native American', 'Arab', 'Indigenous Australian']\n",
    "    pdata[feature].replace(unique,[0,1,2,3,2,2,2],inplace=True)\n",
    "    \n",
    "    return pdata\n",
    "\n",
    "def cat_religion(data):\n",
    "    feature = 'religion'\n",
    "    pdata = data.copy()\n",
    "    unique = ['Other', 'Hindu', 'Agnostic', 'Atheist', 'Christian_Other',\n",
    "       'Christian_Catholic', 'Muslim', 'Buddhist', 'Christian_Protestant',\n",
    "       'Jewish', 'Christian_Mormon', 'Sikh']\n",
    "    pdata[feature].replace(unique,[3,3,1,0,2,2,3,3,2,3,3,3],inplace=True)\n",
    "    \n",
    "    return pdata\n",
    "\n",
    "def cat_num(data):\n",
    "    pdata = data.copy()\n",
    "    pdata = cat_gender(pdata)\n",
    "    pdata = cat_race(pdata)\n",
    "    pdata = cat_religion(pdata)\n",
    "    \n",
    "    return pdata\n",
    "# drop feature\n",
    "def drop_feature(data):\n",
    "    feature_arr = ['index'] \n",
    "    for i in range(20):\n",
    "        feature_arr.append('Q'+chr(i+97)+'A')\n",
    "    for i in range(1,14):\n",
    "        feature_arr.append(f'wr_{i:02d}')\n",
    "    for i in range(1,4):\n",
    "        feature_arr.append(f'wf_{i:02d}')\n",
    "    for i in range(1,11):\n",
    "        feature_arr.append(f'tp{i:02d}')\n",
    "    for i in range(20):\n",
    "        feature_arr.append('Q'+chr(i+97)+'E')\n",
    "\n",
    "    pdata = data.drop(feature_arr,axis=1)\n",
    "    \n",
    "    return pdata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data, datatype):\n",
    "    \n",
    "    pdata = data.copy()\n",
    "    # fill NA\n",
    "    pdata = fill_married(pdata)\n",
    "    pdata = fill_education(pdata)\n",
    "    pdata = fill_engnat(pdata)\n",
    "    pdata = fill_hand(pdata)\n",
    "    # feature engineering\n",
    "    pdata = Mach_score(pdata)\n",
    "    pdata = w_score(pdata)\n",
    "    pdata = TIPI(pdata)\n",
    "    # drop outlier\n",
    "    pdata = drop_outlier(pdata,datatype)\n",
    "    # feature banding\n",
    "    pdata = age_band(pdata)\n",
    "    pdata = family_band(pdata)\n",
    "    pdata = E_band(pdata,10)\n",
    "    # categorical value to numerical value\n",
    "    pdata = cat_num(pdata)\n",
    "    # drop feature\n",
    "    pdata = drop_feature(pdata)\n",
    "    # unify type of data\n",
    "    pdata = pdata.astype(np.int)\n",
    "    \n",
    "    return pdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_auc(model_arr, data, label):\n",
    "    score = np.zeros((data.shape[0],2))\n",
    "    num_model = len(model_arr)\n",
    "    for i in range(num_model):\n",
    "        score += model_arr[i].predict_proba(data)\n",
    "    pred = np.divide(score,num_model)[:,1]\n",
    "    \n",
    "    return roc_auc_score(label, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = train.iloc[38703:,:]\n",
    "train = train.iloc[:38703,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(max_depth_arr, n_estimators_arr, learning_rate_arr, min_child_arr):\n",
    "    opt_auc = 0\n",
    "    opt_para = {}\n",
    "   \n",
    "    train_x = preprocess(train,'train')\n",
    "    train_y = train_x['voted']\n",
    "    train_x = train_x.drop(['voted'],axis=1)\n",
    "    val_x = preprocess(val,'test')\n",
    "    val_y = val_x['voted']\n",
    "    val_x = val_x.drop(['voted'],axis=1)\n",
    "    \n",
    "    for max_depth in max_depth_arr:\n",
    "        for n_estimators in n_estimators_arr:\n",
    "            for learning_rate in learning_rate_arr:\n",
    "                for min_child in min_child_arr:\n",
    "                    print(f'{max_depth}_{n_estimators}_{learning_rate:.3f}_{min_child}', end=' ')\n",
    "                    param = { 'max_depth' : max_depth,\n",
    "                            'n_estimators' : n_estimators,\n",
    "                            'learning_rate' : learning_rate,\n",
    "                             'min_child_weight' : min_child,\n",
    "                            'verbosity' : 0,\n",
    "                            'objective' : 'binary:logistic',\n",
    "                            'booster' : 'gbtree',\n",
    "                            'subsample' : 0.8,\n",
    "                            'colsample_bytree' : 0.8}\n",
    "\n",
    "                    model = XGBClassifier(**param)\n",
    "                    model.fit(train_x, train_y, verbose=False)\n",
    "                    auc = train_auc([model], val_x, val_y) \n",
    "                    print('\\033[34m' + f'{auc:.6f}' + '\\033[0m')\n",
    "                \n",
    "                    if (auc>opt_auc):\n",
    "                        opt_auc = auc\n",
    "                        opt_para = param\n",
    "    print('-'*30)\n",
    "    print(f'{opt_para} = {opt_auc:.6f}')\n",
    "    \n",
    "    return opt_auc, opt_para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7_300_0.012_16 \u001b[34m0.768581\u001b[0m\n",
      "7_300_0.012_17 \u001b[34m0.768382\u001b[0m\n",
      "7_300_0.012_18 \u001b[34m0.768470\u001b[0m\n",
      "7_300_0.012_19 \u001b[34m0.768383\u001b[0m\n",
      "7_300_0.012_20 \u001b[34m0.768317\u001b[0m\n",
      "7_300_0.012_21 \u001b[34m0.768249\u001b[0m\n",
      "7_300_0.012_22 \u001b[34m0.768170\u001b[0m\n",
      "7_300_0.012_23 \u001b[34m0.768304\u001b[0m\n",
      "7_300_0.012_24 \u001b[34m0.768452\u001b[0m\n",
      "7_300_0.012_25 \u001b[34m0.768352\u001b[0m\n",
      "7_300_0.012_26 \u001b[34m0.768330\u001b[0m\n",
      "7_300_0.012_27 \u001b[34m0.768237\u001b[0m\n",
      "7_300_0.012_28 \u001b[34m0.768424\u001b[0m\n",
      "7_300_0.012_29 \u001b[34m0.768574\u001b[0m\n",
      "7_300_0.014_16 \u001b[34m0.768358\u001b[0m\n",
      "7_300_0.014_17 \u001b[34m0.768333\u001b[0m\n",
      "7_300_0.014_18 \u001b[34m0.768177\u001b[0m\n",
      "7_300_0.014_19 \u001b[34m0.768207\u001b[0m\n",
      "7_300_0.014_20 \u001b[34m0.768248\u001b[0m\n",
      "7_300_0.014_21 \u001b[34m0.767997\u001b[0m\n",
      "7_300_0.014_22 \u001b[34m0.768038\u001b[0m\n",
      "7_300_0.014_23 \u001b[34m0.768185\u001b[0m\n",
      "7_300_0.014_24 \u001b[34m0.768099\u001b[0m\n",
      "7_300_0.014_25 \u001b[34m0.767930\u001b[0m\n",
      "7_300_0.014_26 \u001b[34m0.767928\u001b[0m\n",
      "7_300_0.014_27 \u001b[34m0.768216\u001b[0m\n",
      "7_300_0.014_28 \u001b[34m0.768444\u001b[0m\n",
      "7_300_0.014_29 \u001b[34m0.768169\u001b[0m\n",
      "------------------------------\n",
      "{'max_depth': 7, 'n_estimators': 300, 'learning_rate': 0.012, 'min_child_weight': 16, 'verbosity': 0, 'objective': 'binary:logistic', 'booster': 'gbtree', 'subsample': 0.8, 'colsample_bytree': 0.8} = 0.768581\n"
     ]
    }
   ],
   "source": [
    "auc, para = grid_search(max_depth_arr=[7],n_estimators_arr=[300],learning_rate_arr=[0.012,0.014], min_child_arr=range(16,30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
