{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import *\n",
    "import itertools\n",
    "\n",
    "import os\n",
    "\n",
    "import xgboost as xgb \n",
    "from xgboost import plot_importance , XGBClassifier\n",
    "\n",
    "import lightgbm as lgbm\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from keras.utils.np_utils import to_categorical \n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import *\n",
    "\n",
    "from tqdm import tqdm, notebook\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_original = pd.read_csv('./open data/train.csv')\n",
    "test_original = pd.read_csv('./open data/test_x.csv')\n",
    "train = train_original.copy()\n",
    "test = test_original.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = train.iloc[38703:,:]\n",
    "train = train.iloc[:38703,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_outlier(data):\n",
    "    outlier_id = np.where(data['familysize']>=100)[0]\n",
    "    pdata = data.drop(outlier_id)\n",
    "    \n",
    "    return pdata\n",
    "\n",
    "def drop_feature(data):\n",
    "    feature_arr = ['index'] # urban, Q_A, Q_E, wr_, wf_\n",
    "    for i in range(20):\n",
    "        feature_arr.append('Q'+chr(i+97)+'A')\n",
    "    for i in range(1,14):\n",
    "        feature_arr.append(f'wr_{i:02d}')\n",
    "    for i in range(1,4):\n",
    "        feature_arr.append(f'wf_{i:02d}')\n",
    "    for i in range(1,11):\n",
    "        feature_arr.append(f'tp{i:02d}')\n",
    "\n",
    "    pdata = data.drop(feature_arr,axis=1)\n",
    "    \n",
    "    return pdata\n",
    "\n",
    "def age_band(data):\n",
    "    pdata = data.copy()\n",
    "    pdata['age_group'].replace(['10s','20s','30s','40s','50s','60s','+70s'],[1,2,3,4,5,5,5],inplace=True)\n",
    "    \n",
    "    return pdata\n",
    "\n",
    "def cat_gender(data):\n",
    "    feature = 'gender'\n",
    "    pdata = data.copy()\n",
    "    pdata[feature].replace(['Male','Female'],[0,1],inplace=True)\n",
    "    \n",
    "    return pdata\n",
    "\n",
    "def cat_race(data):\n",
    "    feature = 'race'\n",
    "    pdata = data.copy()\n",
    "    unique = ['White', 'Asian', 'Other', 'Black', 'Native American', 'Arab', 'Indigenous Australian']\n",
    "    pdata[feature].replace(unique,[0,1,2,3,2,2,2],inplace=True)\n",
    "    \n",
    "    return pdata\n",
    "\n",
    "def cat_religion(data):\n",
    "    feature = 'religion'\n",
    "    pdata = data.copy()\n",
    "    unique = ['Other', 'Hindu', 'Agnostic', 'Atheist', 'Christian_Other',\n",
    "       'Christian_Catholic', 'Muslim', 'Buddhist', 'Christian_Protestant',\n",
    "       'Jewish', 'Christian_Mormon', 'Sikh']\n",
    "    pdata[feature].replace(unique,[3,3,1,0,2,2,3,3,2,3,3,3],inplace=True)\n",
    "    \n",
    "    return pdata\n",
    "\n",
    "def cat_num(data):\n",
    "    pdata = data.copy()\n",
    "    pdata = cat_gender(pdata)\n",
    "    pdata = cat_race(pdata)\n",
    "    pdata = cat_religion(pdata)\n",
    "    \n",
    "    return pdata\n",
    "\n",
    "def E_band(data, num_band):\n",
    "    pdata = data.copy()\n",
    "    for i in range(20):\n",
    "        col = 'Q'+chr(i+97)+'E'\n",
    "        pdata[col] = pd.qcut(pdata[col],num_band)\n",
    "        unique = pdata[col].unique()\n",
    "        pdata[col].replace(unique,range(num_band),inplace=True)\n",
    "        \n",
    "    return pdata\n",
    "\n",
    "def family_band(data):\n",
    "    pdata = data.copy()\n",
    "    pdata.loc[pdata.familysize >= 4,'familysize'] = 4\n",
    "    \n",
    "    return pdata\n",
    "\n",
    "def fill_married(data):\n",
    "    pdata = data.copy()\n",
    "    pdata.loc[ (pdata.married==0)&(pdata.age_group=='10s'),'married' ] = 1\n",
    "    pdata.loc[ (pdata.married==0)&(pdata.age_group=='20s'),'married' ] = 1\n",
    "    pdata.loc[pdata.married==0,'married'] = 2\n",
    "    \n",
    "    return pdata\n",
    "\n",
    "def fill_education(data):\n",
    "    pdata = data.copy()\n",
    "    pdata.loc[(pdata.education==0)&(pdata.age_group=='10s'),'education'] = 2\n",
    "    pdata.loc[pdata.education==0,'education'] = 3\n",
    "\n",
    "    return pdata\n",
    "\n",
    "def fill_engnat(data):\n",
    "    pdata = data.copy()\n",
    "    pdata.loc[pdata.engnat==0,'engnat'] = 1\n",
    "    \n",
    "    return pdata\n",
    "\n",
    "def fill_hand(data):\n",
    "    pdata = data.copy()\n",
    "    pdata.loc[pdata.hand==0,'hand'] = 1\n",
    "    \n",
    "    return pdata\n",
    "\n",
    "def Mach_score(data):\n",
    "    pdata = data.copy()\n",
    "    Answers = []\n",
    "    for i in range(20):\n",
    "        Answers.append('Q'+chr(97+i)+'A')\n",
    "    reverse_col = ['QeA','QfA','QkA','QqA','QrA','QaA','QdA','QgA','QiA','QnA']\n",
    "    for col in reverse_col:\n",
    "        pdata[col] = -pdata[col]\n",
    "    pdata['Mach_score'] = pdata[Answers].mean(axis=1)\n",
    "    \n",
    "    return pdata\n",
    "\n",
    "def C_score(data):\n",
    "    pdata = data.copy()\n",
    "    Answers = []\n",
    "    for i in range(1,14):\n",
    "        Answers.append(f'wr_{i:02d}')\n",
    "    for i in range(1,4):\n",
    "        pdata[f'wf_{i:02d}'] = -pdata[f'wf_{i:02d}']\n",
    "        Answers.append(f'wf_{i:02d}')\n",
    "    \n",
    "    pdata['C_score'] = pdata[Answers].mean(axis=1)\n",
    "    \n",
    "    return pdata\n",
    "\n",
    "def TIPI_score(data):\n",
    "    pdata = data.copy()\n",
    "    pdata['tp_score_1'] = pdata['tp01'] - pdata['tp06']\n",
    "    pdata['tp_score_2'] = pdata['tp07'] - pdata['tp02']\n",
    "    pdata['tp_score_3'] = pdata['tp03'] - pdata['tp08']\n",
    "    pdata['tp_score_4'] = pdata['tp09'] - pdata['tp04']\n",
    "    pdata['tp_score_5'] = pdata['tp05'] - pdata['tp10']\n",
    "    \n",
    "    return pdata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    \n",
    "    pdata = data.copy()\n",
    "    pdata = fill_married(pdata)\n",
    "    pdata = fill_education(pdata)\n",
    "    pdata = fill_engnat(pdata)\n",
    "    pdata = fill_hand(pdata)\n",
    "    pdata = age_band(pdata)\n",
    "    pdata = family_band(pdata)\n",
    "    pdata = cat_num(pdata)\n",
    "    pdata = E_band(pdata,10)\n",
    "    pdata = Mach_score(pdata)\n",
    "    pdata = C_score(pdata)\n",
    "    pdata = TIPI_score(pdata)\n",
    "    \n",
    "    pdata = drop_feature(pdata)\n",
    "    pdata = pdata.astype(np.float32)\n",
    "    \n",
    "    return pdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_auc(model_arr, data, label):\n",
    "    score = np.zeros((data.shape[0],2))\n",
    "    num_model = len(model_arr)\n",
    "    for i in range(num_model):\n",
    "        score += model_arr[i].predict_proba(data)\n",
    "    pred = np.divide(score,num_model)[:,1]\n",
    "    \n",
    "    return roc_auc_score(label, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(max_depth_arr, n_estimators_arr, learning_rate_arr):\n",
    "    opt_auc = 0\n",
    "    opt_para = []\n",
    "   \n",
    "    train_x = drop_outlier(train)\n",
    "    train_x = preprocess(train_x)\n",
    "    train_y = train_x['voted']\n",
    "    train_x = train_x.drop(['voted'],axis=1)\n",
    "    val_x = preprocess(val)\n",
    "    val_y = val_x['voted']\n",
    "    val_x = val_x.drop(['voted'],axis=1)\n",
    "    \n",
    "    for max_depth in max_depth_arr:\n",
    "        for n_estimators in n_estimators_arr:\n",
    "            for learning_rate in learning_rate_arr:\n",
    "                \n",
    "                print(f'{max_depth}_{n_estimators}_{learning_rate}', end=' ')\n",
    "                model = XGBClassifier(max_depth=max_depth,learning_rate=learning_rate, booster='gbtree',n_estimators=n_estimators, objective='binary:logistic')\n",
    "                model.fit(train_x, train_y, verbose=False)\n",
    "                auc = train_auc([model], val_x, val_y) \n",
    "                print('\\033[34m' + f'{auc:.4f}' + '\\033[0m')\n",
    "                \n",
    "                if (auc>opt_auc):\n",
    "                    opt_auc = auc\n",
    "                    opt_para = [max_depth, n_estimators, learning_rate]\n",
    "    print('\\033[41m' + f'{opt_para} : {opt_auc:.4f}' + '\\033[0m')\n",
    "    \n",
    "    return opt_auc, opt_para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4_400_0.015 \u001b[34m0.7652\u001b[0m\n",
      "4_400_0.02 \u001b[34m0.7653\u001b[0m\n",
      "4_400_0.025 \u001b[34m0.7656\u001b[0m\n",
      "4_500_0.015 \u001b[34m0.7651\u001b[0m\n",
      "4_500_0.02 \u001b[34m0.7654\u001b[0m\n",
      "4_500_0.025 \u001b[34m0.7652\u001b[0m\n",
      "4_600_0.015 \u001b[34m0.7652\u001b[0m\n",
      "4_600_0.02 \u001b[34m0.7655\u001b[0m\n",
      "4_600_0.025 \u001b[34m0.7652\u001b[0m\n",
      "5_400_0.015 \u001b[34m0.7657\u001b[0m\n",
      "5_400_0.02 \u001b[34m0.7654\u001b[0m\n",
      "5_400_0.025 \u001b[34m0.7649\u001b[0m\n",
      "5_500_0.015 \u001b[34m0.7654\u001b[0m\n",
      "5_500_0.02 \u001b[34m0.7657\u001b[0m\n",
      "5_500_0.025 \u001b[34m0.7647\u001b[0m\n",
      "5_600_0.015 \u001b[34m0.7652\u001b[0m\n",
      "5_600_0.02 \u001b[34m0.7652\u001b[0m\n",
      "5_600_0.025 \u001b[34m0.7642\u001b[0m\n",
      "6_400_0.015 \u001b[34m0.7650\u001b[0m\n",
      "6_400_0.02 \u001b[34m0.7644\u001b[0m\n",
      "6_400_0.025 \u001b[34m0.7644\u001b[0m\n",
      "6_500_0.015 \u001b[34m0.7648\u001b[0m\n",
      "6_500_0.02 \u001b[34m0.7640\u001b[0m\n",
      "6_500_0.025 \u001b[34m0.7636\u001b[0m\n",
      "6_600_0.015 \u001b[34m0.7641\u001b[0m\n",
      "6_600_0.02 \u001b[34m0.7637\u001b[0m\n",
      "6_600_0.025 \u001b[34m0.7621\u001b[0m\n",
      "\u001b[41m0.7657 : [5, 500, 0.02]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "auc, para = grid_search(max_depth_arr=[4,5,6],n_estimators_arr=[400,500,600],learning_rate_arr=[0.015,0.02,0.025])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
