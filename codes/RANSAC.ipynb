{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "\n",
    "import xgboost as xgb \n",
    "from xgboost import plot_importance , XGBClassifier\n",
    "\n",
    "import lightgbm as lgbm\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_original = pd.read_csv('./open data/train.csv')\n",
    "test_original = pd.read_csv('./open data/test_x.csv')\n",
    "train = train_original.copy()\n",
    "test = test_original.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill NA\n",
    "def fill_married(data):\n",
    "    pdata = data.copy()\n",
    "    pdata.loc[ (pdata.married==0)&(pdata.age_group=='10s'),'married' ] = 1\n",
    "    pdata.loc[ (pdata.married==0)&(pdata.age_group=='20s'),'married' ] = 1\n",
    "    pdata.loc[pdata.married==0,'married'] = 2\n",
    "    \n",
    "    return pdata\n",
    "\n",
    "def fill_education(data):\n",
    "    pdata = data.copy()\n",
    "    pdata.loc[(pdata.education==0)&(pdata.age_group=='10s'),'education'] = 2\n",
    "    pdata.loc[pdata.education==0,'education'] = 3\n",
    "\n",
    "    return pdata\n",
    "\n",
    "def fill_engnat(data):\n",
    "    pdata = data.copy()\n",
    "    pdata.loc[pdata.engnat==0,'engnat'] = 1\n",
    "    \n",
    "    return pdata\n",
    "\n",
    "def fill_hand(data):\n",
    "    pdata = data.copy()\n",
    "    pdata.loc[pdata.hand==0,'hand'] = 1\n",
    "    \n",
    "    return pdata\n",
    "# feature engineering\n",
    "def Mach_score(data):\n",
    "    pdata = data.copy()\n",
    "    Answers = []\n",
    "    for i in range(20):\n",
    "        Answers.append('Q'+chr(97+i)+'A')\n",
    "    reverse_col = ['QeA','QfA','QkA','QqA','QrA','QaA','QdA','QgA','QiA','QnA']\n",
    "    for col in reverse_col:\n",
    "        pdata[col] = -pdata[col]\n",
    "    pdata['Mach_score'] = pdata[Answers].sum(axis=1)\n",
    "    \n",
    "    return pdata\n",
    "\n",
    "def w_score(data):\n",
    "    pdata = data.copy()\n",
    "    wr = []\n",
    "    wf = []\n",
    "    for i in range(1,14):\n",
    "        wr.append(f'wr_{i:02d}')\n",
    "    for i in range(1,4):\n",
    "        wf.append(f'wf_{i:02d}')\n",
    "    \n",
    "    pdata['wr'] = pdata[wr].sum(axis=1)\n",
    "    pdata['wf'] = pdata[wf].sum(axis=1)\n",
    "    \n",
    "    return pdata\n",
    "\n",
    "def TIPI(data):\n",
    "    pdata = data.copy()\n",
    "    pdata['tp_score_1'] = pdata['tp01'] - pdata['tp06']\n",
    "    pdata['tp_score_2'] = pdata['tp07'] - pdata['tp02']\n",
    "    pdata['tp_score_3'] = pdata['tp03'] - pdata['tp08']\n",
    "    pdata['tp_score_4'] = pdata['tp09'] - pdata['tp04']\n",
    "    pdata['tp_score_5'] = pdata['tp05'] - pdata['tp10']\n",
    "    \n",
    "    return pdata\n",
    "\n",
    "# drop outlier\n",
    "def drop_outlier(data, datatype):\n",
    "    \n",
    "    assert datatype == 'train' or datatype=='test', 'Wrong data type given'\n",
    "    \n",
    "    pdata = data.copy()\n",
    "    if datatype=='train':\n",
    "        \n",
    "        out_arr = []\n",
    "        out_arr.append( np.where(data['familysize']>=16)[0] )\n",
    "        out_arr.append( np.where(data.wr<=3)[0] )\n",
    "        out_arr.append( np.where(data.wf>=2)[0] )\n",
    "\n",
    "        out = []\n",
    "        for outarr in out_arr:\n",
    "            out = np.union1d(out, outarr)\n",
    "\n",
    "        pdata = data.drop(out)\n",
    "    \n",
    "    return pdata\n",
    "# feature banding\n",
    "def age_band(data):\n",
    "    pdata = data.copy()\n",
    "    pdata['age_group'].replace(['10s','20s','30s','40s','50s','60s','+70s'],[1,2,3,4,5,5,5],inplace=True)\n",
    "    \n",
    "    return pdata\n",
    "\n",
    "def E_band(data, num_band):\n",
    "    pdata = data.copy()\n",
    "    for i in range(20):\n",
    "        col = 'Q'+chr(i+97)+'E'\n",
    "        pdata[col] = pd.qcut(pdata[col],num_band)\n",
    "        unique = pdata[col].unique()\n",
    "        pdata[col].replace(unique,range(num_band),inplace=True)\n",
    "        \n",
    "    return pdata\n",
    "\n",
    "def family_band(data):\n",
    "    pdata = data.copy()\n",
    "    pdata.loc[pdata.familysize >= 4,'familysize'] = 4\n",
    "    \n",
    "    return pdata\n",
    "# categorical value to numerical value\n",
    "def cat_gender(data):\n",
    "    feature = 'gender'\n",
    "    pdata = data.copy()\n",
    "    pdata[feature].replace(['Male','Female'],[0,1],inplace=True)\n",
    "    \n",
    "    return pdata\n",
    "\n",
    "def cat_race(data):\n",
    "    feature = 'race'\n",
    "    pdata = data.copy()\n",
    "    unique = ['White', 'Asian', 'Other', 'Black', 'Native American', 'Arab', 'Indigenous Australian']\n",
    "    pdata[feature].replace(unique,[0,1,2,3,2,2,2],inplace=True)\n",
    "    \n",
    "    return pdata\n",
    "\n",
    "def cat_religion(data):\n",
    "    feature = 'religion'\n",
    "    pdata = data.copy()\n",
    "    unique = ['Other', 'Hindu', 'Agnostic', 'Atheist', 'Christian_Other',\n",
    "       'Christian_Catholic', 'Muslim', 'Buddhist', 'Christian_Protestant',\n",
    "       'Jewish', 'Christian_Mormon', 'Sikh']\n",
    "    pdata[feature].replace(unique,[3,3,1,0,2,2,3,3,2,3,3,3],inplace=True)\n",
    "    \n",
    "    return pdata\n",
    "\n",
    "def cat_num(data):\n",
    "    pdata = data.copy()\n",
    "    pdata = cat_gender(pdata)\n",
    "    pdata = cat_race(pdata)\n",
    "    pdata = cat_religion(pdata)\n",
    "    \n",
    "    return pdata\n",
    "# drop feature\n",
    "def drop_feature(data):\n",
    "    feature_arr = ['index','wf'] \n",
    "    for i in range(20):\n",
    "        feature_arr.append('Q'+chr(i+97)+'A')\n",
    "    for i in range(1,14):\n",
    "        feature_arr.append(f'wr_{i:02d}')\n",
    "    for i in range(1,4):\n",
    "        feature_arr.append(f'wf_{i:02d}')\n",
    "    for i in range(1,11):\n",
    "        feature_arr.append(f'tp{i:02d}')\n",
    "    for i in range(20):\n",
    "        feature_arr.append('Q'+chr(i+97)+'E')\n",
    "\n",
    "    pdata = data.drop(feature_arr,axis=1)\n",
    "    \n",
    "    return pdata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data, datatype):\n",
    "    \n",
    "    pdata = data.copy()\n",
    "    # fill NA\n",
    "    pdata = fill_married(pdata)\n",
    "    pdata = fill_education(pdata)\n",
    "    pdata = fill_engnat(pdata)\n",
    "    pdata = fill_hand(pdata)\n",
    "    # feature engineering\n",
    "    pdata = Mach_score(pdata)\n",
    "    pdata = w_score(pdata)\n",
    "    pdata = TIPI(pdata)\n",
    "    # drop outlier\n",
    "    pdata = drop_outlier(pdata,datatype)\n",
    "    # feature banding\n",
    "    pdata = age_band(pdata)\n",
    "    pdata = family_band(pdata)\n",
    "    pdata = E_band(pdata,10)\n",
    "    # categorical value to numerical value\n",
    "    pdata = cat_num(pdata)\n",
    "    # drop feature\n",
    "    pdata = drop_feature(pdata)\n",
    "    # unify type of data\n",
    "    pdata = pdata.astype(np.int)\n",
    "    \n",
    "    return pdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_auc(model_arr, data, label):\n",
    "    score = np.zeros((data.shape[0],2))\n",
    "    num_model = len(model_arr)\n",
    "    for i in range(num_model):\n",
    "        score += model_arr[i].predict_proba(data)\n",
    "    pred = np.divide(score,num_model)[:,1]\n",
    "    \n",
    "    return roc_auc_score(label, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submission(test_data, model_arr,file_name):\n",
    "    score = np.zeros((test_data.shape[0],2))\n",
    "    num_model = len(model_arr)\n",
    "    for i in range(num_model):\n",
    "        score += model_arr[i].predict_proba(test_data)\n",
    "    pred = np.divide(score,num_model)[:,1]\n",
    "    data = {'index':test['index'],'voted':pred}\n",
    "    submission = DataFrame(data)\n",
    "    submission.to_csv('./submission/'+file_name+'.csv',index=False)\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANSAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = { 'max_depth' : 8,\n",
    "        'n_estimators' : 200,\n",
    "        'learning_rate' : 0.1,\n",
    "        'min_child_weight' : 6,\n",
    "        'colsample_bytree' : 0.8,\n",
    "        'verbosity' : 0,\n",
    "        'objective' : 'binary:logistic',\n",
    "        'booster' : 'gbtree',\n",
    "        'subsample' : 0.8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ransac(num_iter, num_sample, param):\n",
    "\n",
    "    best = None\n",
    "    consensus = 0\n",
    "    \n",
    "    preprocessed = preprocess(train,'train')\n",
    "    val_x = preprocessed.copy()\n",
    "    val_y = val_x['voted']\n",
    "    val_x = val_x.drop(['voted'],axis=1)\n",
    "\n",
    "    for i in range(num_iter):\n",
    "        print(f'{i}', end=' ')\n",
    "        train_sample = preprocessed.sample(n=num_sample, random_state=None, axis=0)\n",
    "\n",
    "        train_y = train_sample['voted']\n",
    "        train_x = train_sample.drop(['voted'],axis=1)\n",
    "\n",
    "        model = XGBClassifier(**param)\n",
    "        model.fit(train_x, train_y, verbose=False)\n",
    "        \n",
    "        auc = train_auc([model],val_x,val_y)\n",
    "\n",
    "        if (consensus < auc):\n",
    "            consensus = auc\n",
    "            best = model\n",
    "            print('\\033[31m' + f'{auc:.6f}' + '\\033[0m')\n",
    "        else:\n",
    "            print(f'{auc:.6f}')\n",
    "    \n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \u001b[31m0.762431\u001b[0m\n",
      "1 0.760228\n",
      "2 0.759583\n",
      "3 0.760719\n",
      "4 0.757064\n",
      "5 0.757751\n",
      "6 0.761758\n",
      "7 0.757790\n",
      "8 0.759629\n",
      "9 \u001b[31m0.763490\u001b[0m\n",
      "10 0.761580\n",
      "11 0.761660\n",
      "12 0.762541\n",
      "13 0.761518\n",
      "14 0.754403\n",
      "15 0.762266\n",
      "16 0.758283\n",
      "17 0.761585\n",
      "18 0.760387\n",
      "19 0.760291\n",
      "20 0.760000\n",
      "21 0.760883\n",
      "22 0.761406\n",
      "23 0.761381\n",
      "24 0.757761\n",
      "25 0.759871\n",
      "26 0.757934\n",
      "27 0.761508\n",
      "28 0.759333\n",
      "29 0.760935\n",
      "30 0.759978\n",
      "31 0.760830\n",
      "32 0.755960\n",
      "33 0.759678\n",
      "34 0.760109\n",
      "35 0.759323\n",
      "36 0.759856\n",
      "37 0.756617\n",
      "38 0.759054\n",
      "39 0.759449\n",
      "40 0.760056\n",
      "41 0.762122\n",
      "42 0.762468\n",
      "43 0.759640\n",
      "44 0.757213\n",
      "45 0.761593\n",
      "46 0.759633\n",
      "47 0.762071\n",
      "48 0.760818\n",
      "49 0.761821\n",
      "50 0.760405\n",
      "51 0.763151\n",
      "52 0.758293\n",
      "53 0.761369\n",
      "54 0.762555\n",
      "55 0.761665\n",
      "56 0.760186\n",
      "57 0.759711\n",
      "58 0.758415\n",
      "59 0.759490\n",
      "60 0.759560\n",
      "61 0.759374\n",
      "62 0.759700\n",
      "63 0.756847\n",
      "64 0.760245\n",
      "65 0.761260\n",
      "66 0.760347\n",
      "67 0.756851\n",
      "68 0.759542\n",
      "69 0.756289\n",
      "70 0.756910\n",
      "71 0.760083\n",
      "72 0.761856\n",
      "73 0.761873\n",
      "74 0.761480\n",
      "75 0.760382\n",
      "76 0.760989\n",
      "77 0.759864\n",
      "78 0.755864\n",
      "79 0.757858\n",
      "80 0.761213\n",
      "81 0.762188\n",
      "82 0.762048\n",
      "83 0.760282\n",
      "84 0.760142\n",
      "85 0.759550\n",
      "86 0.759499\n",
      "87 0.761727\n",
      "88 0.760124\n",
      "89 0.758321\n",
      "90 0.760225\n",
      "91 0.760752\n",
      "92 0.760004\n",
      "93 0.761038\n",
      "94 0.761679\n",
      "95 0.755710\n",
      "96 0.762584\n",
      "97 0.760967\n",
      "98 0.759594\n",
      "99 0.759747\n",
      "100 0.759080\n",
      "101 0.760571\n",
      "102 0.762054\n",
      "103 0.759550\n",
      "104 0.760945\n",
      "105 0.759387\n",
      "106 0.758173\n",
      "107 \u001b[31m0.763877\u001b[0m\n",
      "108 0.756692\n",
      "109 0.759144\n",
      "110 0.761838\n",
      "111 0.759260\n",
      "112 0.759934\n",
      "113 0.758948\n",
      "114 0.755048\n",
      "115 0.759256\n",
      "116 0.760102\n",
      "117 0.758972\n",
      "118 0.761560\n",
      "119 0.758503\n",
      "120 0.758779\n",
      "121 0.759078\n",
      "122 0.760434\n",
      "123 0.762925\n",
      "124 0.757599\n",
      "125 0.757079\n",
      "126 0.758495\n",
      "127 0.762178\n",
      "128 0.753076\n",
      "129 0.761516\n",
      "130 0.759092\n",
      "131 0.759610\n",
      "132 0.757337\n",
      "133 0.762074\n",
      "134 0.760072\n",
      "135 0.760289\n",
      "136 0.758342\n",
      "137 0.757419\n",
      "138 0.759297\n",
      "139 0.758693\n",
      "140 0.761515\n",
      "141 0.759837\n",
      "142 0.758381\n",
      "143 0.759670\n",
      "144 0.759474\n",
      "145 0.759109\n",
      "146 0.757546\n",
      "147 0.759206\n",
      "148 0.759024\n",
      "149 0.757088\n",
      "150 0.758108\n",
      "151 0.757878\n",
      "152 0.758922\n",
      "153 0.759843\n",
      "154 0.760183\n",
      "155 0.761964\n",
      "156 0.759727\n",
      "157 0.760264\n",
      "158 0.758866\n",
      "159 0.761864\n",
      "160 \u001b[31m0.764402\u001b[0m\n",
      "161 0.758024\n",
      "162 0.761709\n",
      "163 0.757700\n",
      "164 0.762943\n",
      "165 0.760702\n",
      "166 0.759556\n",
      "167 0.760331\n",
      "168 0.760194\n",
      "169 0.760468\n",
      "170 0.757462\n",
      "171 0.760850\n",
      "172 0.761367\n",
      "173 0.760456\n",
      "174 0.759307\n",
      "175 0.755111\n",
      "176 0.761962\n",
      "177 0.758705\n",
      "178 0.759974\n",
      "179 0.759917\n",
      "180 0.757730\n",
      "181 0.760409\n",
      "182 0.760779\n",
      "183 0.760736\n",
      "184 0.760736\n",
      "185 0.762847\n",
      "186 0.763205\n",
      "187 0.761041\n",
      "188 0.759812\n",
      "189 0.762286\n",
      "190 0.758530\n",
      "191 0.759166\n",
      "192 0.758946\n",
      "193 0.757881\n",
      "194 0.760454\n",
      "195 0.760880\n",
      "196 0.762605\n",
      "197 0.760422\n",
      "198 0.756855\n",
      "199 \u001b[31m0.765345\u001b[0m\n",
      "200 0.757877\n",
      "201 0.757897\n",
      "202 0.763926\n",
      "203 0.762297\n",
      "204 0.761233\n",
      "205 0.757669\n",
      "206 0.758354\n",
      "207 0.761077\n",
      "208 0.754523\n",
      "209 0.760558\n",
      "210 0.760012\n",
      "211 0.759816\n",
      "212 0.758679\n",
      "213 0.761130\n",
      "214 0.764210\n",
      "215 0.759180\n",
      "216 0.757634\n",
      "217 0.761505\n",
      "218 0.756425\n",
      "219 0.758980\n",
      "220 0.759379\n",
      "221 0.760924\n",
      "222 0.757644\n",
      "223 0.761995\n",
      "224 0.761702\n",
      "225 0.758125\n",
      "226 0.762883\n",
      "227 0.761957\n",
      "228 0.758262\n",
      "229 0.761906\n",
      "230 0.757061\n",
      "231 0.757779\n",
      "232 0.756376\n",
      "233 0.758673\n",
      "234 0.760863\n",
      "235 0.762960\n",
      "236 0.759065\n",
      "237 0.761029\n",
      "238 0.761562\n",
      "239 0.759302\n",
      "240 0.761080\n",
      "241 0.761517\n",
      "242 0.759352\n",
      "243 0.754930\n",
      "244 0.757899\n",
      "245 0.764382\n",
      "246 0.758599\n",
      "247 0.757368\n",
      "248 0.760141\n",
      "249 0.761373\n",
      "250 0.759153\n",
      "251 0.761602\n",
      "252 0.754734\n",
      "253 0.758008\n",
      "254 0.760551\n",
      "255 0.757967\n",
      "256 0.758928\n",
      "257 0.758818\n",
      "258 0.763757\n",
      "259 0.759605\n",
      "260 0.761965\n",
      "261 0.760492\n",
      "262 0.759743\n",
      "263 0.760695\n",
      "264 0.759740\n",
      "265 0.762118\n",
      "266 0.762253\n",
      "267 0.762858\n",
      "268 0.761111\n",
      "269 0.758146\n",
      "270 0.760543\n",
      "271 0.760812\n",
      "272 0.760578\n",
      "273 0.759972\n",
      "274 0.760215\n",
      "275 0.756756\n",
      "276 0.758614\n",
      "277 0.758357\n",
      "278 0.761687\n",
      "279 0.759229\n",
      "280 0.760700\n",
      "281 0.761437\n",
      "282 0.761244\n",
      "283 0.759065\n",
      "284 0.758858\n",
      "285 0.760045\n",
      "286 0.761186\n",
      "287 0.760598\n",
      "288 0.759182\n",
      "289 0.757871\n",
      "290 0.760542\n",
      "291 0.760735\n",
      "292 0.756569\n",
      "293 0.759160\n",
      "294 0.759370\n",
      "295 0.759910\n",
      "296 0.759478\n",
      "297 0.759868\n",
      "298 0.759325\n",
      "299 0.760589\n",
      "300 0.757415\n",
      "301 0.761260\n",
      "302 0.758435\n",
      "303 0.759794\n",
      "304 0.761179\n",
      "305 0.762618\n",
      "306 0.758051\n",
      "307 0.760718\n",
      "308 0.754422\n",
      "309 0.759403\n",
      "310 0.759814\n",
      "311 0.758861\n",
      "312 0.756616\n",
      "313 0.760342\n",
      "314 0.761835\n",
      "315 0.758270\n",
      "316 0.761803\n",
      "317 0.761273\n",
      "318 0.760586\n",
      "319 0.761799\n",
      "320 0.758303\n",
      "321 0.758260\n",
      "322 0.759996\n",
      "323 0.759704\n",
      "324 0.760759\n",
      "325 0.761652\n",
      "326 0.761778\n",
      "327 0.759334\n",
      "328 0.760873\n",
      "329 0.757916\n",
      "330 0.760183\n",
      "331 0.762068\n",
      "332 0.759440\n",
      "333 0.760397\n",
      "334 0.760538\n",
      "335 0.759248\n",
      "336 0.757716\n",
      "337 0.758616\n",
      "338 0.759178\n",
      "339 0.763604\n",
      "340 0.763028\n",
      "341 0.757688\n",
      "342 0.760358\n",
      "343 0.762013\n",
      "344 0.762671\n",
      "345 0.760152\n",
      "346 0.759533\n",
      "347 0.759207\n",
      "348 0.760430\n",
      "349 0.759979\n",
      "350 0.756120\n",
      "351 0.757263\n",
      "352 0.760964\n",
      "353 0.757296\n",
      "354 0.761367\n",
      "355 0.758634\n",
      "356 0.757891\n",
      "357 0.762208\n",
      "358 0.760030\n",
      "359 0.761702\n",
      "360 0.758802\n",
      "361 0.760914\n",
      "362 0.762032\n",
      "363 0.759625\n",
      "364 0.759512\n",
      "365 0.759273\n",
      "366 0.757354\n",
      "367 0.764465\n",
      "368 0.761014\n",
      "369 0.757068\n",
      "370 0.762627\n",
      "371 0.760667\n",
      "372 0.761810\n",
      "373 0.755583\n",
      "374 0.757665\n",
      "375 0.759661\n",
      "376 0.759246\n",
      "377 0.756649\n",
      "378 0.761709\n",
      "379 0.759530\n",
      "380 0.761564\n",
      "381 0.757223\n",
      "382 0.761686\n",
      "383 0.758557\n",
      "384 0.761596\n",
      "385 0.759908\n",
      "386 0.759811\n",
      "387 0.758668\n",
      "388 0.759379\n",
      "389 0.759375\n",
      "390 0.761315\n",
      "391 0.759985\n",
      "392 0.761760\n",
      "393 0.759688\n",
      "394 0.759480\n",
      "395 0.755694\n",
      "396 0.758871\n",
      "397 0.761011\n",
      "398 0.763419\n",
      "399 0.758915\n",
      "400 0.755612\n",
      "401 0.759117\n",
      "402 0.761086\n",
      "403 0.760214\n",
      "404 0.761453\n",
      "405 0.760815\n",
      "406 0.757614\n",
      "407 0.761525\n",
      "408 0.761340\n",
      "409 0.758147\n",
      "410 0.759778\n",
      "411 0.760629\n",
      "412 0.760351\n",
      "413 0.761411\n",
      "414 0.760521\n",
      "415 0.759606\n",
      "416 0.763742\n",
      "417 0.761192\n",
      "418 0.759713\n",
      "419 0.762038\n",
      "420 0.765094\n",
      "421 0.758546\n",
      "422 0.759285\n",
      "423 0.762681\n",
      "424 0.759607\n",
      "425 0.759914\n",
      "426 0.758836\n",
      "427 0.757993\n",
      "428 0.759921\n",
      "429 0.757950\n",
      "430 0.762932\n",
      "431 0.758635\n",
      "432 0.762109\n",
      "433 0.761802\n",
      "434 0.762392\n",
      "435 0.760250\n",
      "436 0.757310\n",
      "437 0.759908\n",
      "438 0.757849\n",
      "439 0.755928\n",
      "440 0.759863\n",
      "441 0.761478\n",
      "442 0.762388\n",
      "443 0.760453\n",
      "444 0.760699\n",
      "445 0.755665\n",
      "446 0.762051\n",
      "447 0.758256\n",
      "448 0.764413\n",
      "449 0.758923\n",
      "450 0.760990\n",
      "451 0.760539\n",
      "452 0.758639\n",
      "453 0.757979\n",
      "454 0.760225\n",
      "455 0.759364\n",
      "456 0.758184\n",
      "457 0.757885\n",
      "458 0.760480\n",
      "459 0.759878\n",
      "460 0.759192\n",
      "461 0.762244\n",
      "462 0.759392\n",
      "463 0.760235\n",
      "464 0.758771\n",
      "465 0.758131\n",
      "466 0.760903\n",
      "467 0.757845\n",
      "468 0.759817\n",
      "469 0.758771\n",
      "470 0.759714\n",
      "471 0.760570\n",
      "472 0.757928\n",
      "473 0.761196\n",
      "474 0.763216\n",
      "475 0.761547\n",
      "476 0.763259\n",
      "477 0.762933\n",
      "478 0.762299\n",
      "479 0.759355\n",
      "480 0.764398\n",
      "481 0.757569\n",
      "482 0.760009\n",
      "483 0.757153\n",
      "484 0.759828\n",
      "485 0.758527\n",
      "486 0.760285\n",
      "487 0.762036\n",
      "488 0.755820\n",
      "489 0.759929\n",
      "490 0.759341\n",
      "491 0.757603\n",
      "492 0.760739\n",
      "493 0.761788\n",
      "494 0.758836\n",
      "495 0.758614\n",
      "496 0.758580\n",
      "497 0.758897\n",
      "498 0.758223\n",
      "499 0.761472\n"
     ]
    }
   ],
   "source": [
    "ransac_model = ransac(num_iter=200, num_sample=1000, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.60888022, 0.80811137, 0.53799826, ..., 0.33056721, 0.45142457,\n",
       "       0.64186668])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission(preprocess(test,'test'),[ransac_model],f'ransac_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'QaA', 'QaE', 'QbA', 'QbE', 'QcA', 'QcE', 'QdA', 'QdE', 'QeA',\n",
       "       'QeE', 'QfA', 'QfE', 'QgA', 'QgE', 'QhA', 'QhE', 'QiA', 'QiE', 'QjA',\n",
       "       'QjE', 'QkA', 'QkE', 'QlA', 'QlE', 'QmA', 'QmE', 'QnA', 'QnE', 'QoA',\n",
       "       'QoE', 'QpA', 'QpE', 'QqA', 'QqE', 'QrA', 'QrE', 'QsA', 'QsE', 'QtA',\n",
       "       'QtE', 'age_group', 'education', 'engnat', 'familysize', 'gender',\n",
       "       'hand', 'married', 'race', 'religion', 'tp01', 'tp02', 'tp03', 'tp04',\n",
       "       'tp05', 'tp06', 'tp07', 'tp08', 'tp09', 'tp10', 'urban', 'voted',\n",
       "       'wf_01', 'wf_02', 'wf_03', 'wr_01', 'wr_02', 'wr_03', 'wr_04', 'wr_05',\n",
       "       'wr_06', 'wr_07', 'wr_08', 'wr_09', 'wr_10', 'wr_11', 'wr_12', 'wr_13'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>QaA</th>\n",
       "      <th>QaE</th>\n",
       "      <th>QbA</th>\n",
       "      <th>QbE</th>\n",
       "      <th>QcA</th>\n",
       "      <th>QcE</th>\n",
       "      <th>QdA</th>\n",
       "      <th>QdE</th>\n",
       "      <th>QeA</th>\n",
       "      <th>...</th>\n",
       "      <th>wr_04</th>\n",
       "      <th>wr_05</th>\n",
       "      <th>wr_06</th>\n",
       "      <th>wr_07</th>\n",
       "      <th>wr_08</th>\n",
       "      <th>wr_09</th>\n",
       "      <th>wr_10</th>\n",
       "      <th>wr_11</th>\n",
       "      <th>wr_12</th>\n",
       "      <th>wr_13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>1.0</td>\n",
       "      <td>561</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2176</td>\n",
       "      <td>5.0</td>\n",
       "      <td>975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>668</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>153</td>\n",
       "      <td>5.0</td>\n",
       "      <td>499</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1557</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1009</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2636</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>168</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1455</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3144</td>\n",
       "      <td>1.0</td>\n",
       "      <td>973</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1265</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>253</td>\n",
       "      <td>3.0</td>\n",
       "      <td>514</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2151</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2532</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2097</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>320</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1328</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2907</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2420</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1770</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45106</th>\n",
       "      <td>45106</td>\n",
       "      <td>3.0</td>\n",
       "      <td>360</td>\n",
       "      <td>5.0</td>\n",
       "      <td>861</td>\n",
       "      <td>3.0</td>\n",
       "      <td>886</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2507</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45194</th>\n",
       "      <td>45194</td>\n",
       "      <td>1.0</td>\n",
       "      <td>775</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1729</td>\n",
       "      <td>5.0</td>\n",
       "      <td>928</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1271</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45224</th>\n",
       "      <td>45224</td>\n",
       "      <td>1.0</td>\n",
       "      <td>197</td>\n",
       "      <td>5.0</td>\n",
       "      <td>401</td>\n",
       "      <td>5.0</td>\n",
       "      <td>601</td>\n",
       "      <td>1.0</td>\n",
       "      <td>452</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45382</th>\n",
       "      <td>45382</td>\n",
       "      <td>2.0</td>\n",
       "      <td>535</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1870</td>\n",
       "      <td>4.0</td>\n",
       "      <td>889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1126</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45513</th>\n",
       "      <td>45513</td>\n",
       "      <td>4.0</td>\n",
       "      <td>392</td>\n",
       "      <td>1.0</td>\n",
       "      <td>794</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2781</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1042</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2217 rows Ã— 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  QaA   QaE  QbA   QbE  QcA   QcE  QdA   QdE  QeA  ...  wr_04  \\\n",
       "96        96  1.0   561  1.0  2176  5.0   975  1.0   668  2.0  ...      0   \n",
       "153      153  5.0   499  5.0  1557  5.0  1009  1.0  2636  5.0  ...      1   \n",
       "168      168  3.0  1455  1.0  3144  1.0   973  1.0  1265  3.0  ...      1   \n",
       "253      253  3.0   514  2.0  2151  3.0  2532  1.0  2097  2.0  ...      1   \n",
       "320      320  2.0  1328  1.0  2907  5.0  2420  1.0  1770  5.0  ...      1   \n",
       "...      ...  ...   ...  ...   ...  ...   ...  ...   ...  ...  ...    ...   \n",
       "45106  45106  3.0   360  5.0   861  3.0   886  3.0  2507  1.0  ...      0   \n",
       "45194  45194  1.0   775  5.0  1729  5.0   928  1.0  1271  1.0  ...      1   \n",
       "45224  45224  1.0   197  5.0   401  5.0   601  1.0   452  1.0  ...      1   \n",
       "45382  45382  2.0   535  4.0  1870  4.0   889  1.0  1126  5.0  ...      1   \n",
       "45513  45513  4.0   392  1.0   794  2.0  2781  4.0  1042  4.0  ...      0   \n",
       "\n",
       "       wr_05  wr_06  wr_07  wr_08  wr_09  wr_10  wr_11  wr_12  wr_13  \n",
       "96         1      0      1      1      0      1      0      1      1  \n",
       "153        1      1      1      1      0      1      1      1      1  \n",
       "168        1      0      1      1      0      1      0      1      1  \n",
       "253        0      1      1      1      1      1      0      1      1  \n",
       "320        1      1      0      1      0      1      1      1      1  \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "45106      0      0      1      1      0      1      0      1      0  \n",
       "45194      1      0      1      1      0      1      0      1      1  \n",
       "45224      1      0      1      1      1      1      1      1      1  \n",
       "45382      1      0      1      1      0      1      1      1      1  \n",
       "45513      0      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[2217 rows x 78 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = DataFrame()\n",
    "for i in range(1,8):\n",
    "    df = pd.concat([df, train[train['tp'+f'{i:02d}']==7]],axis=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
